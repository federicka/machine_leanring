# machine_leanring
some SIMPLE BUT PRACTICAL summary and code for ML

#Naive Bayes for classification, rely on independent asumption but works well for large dataset.(coz loss function is the number of 
correct and incorrect number instead of mse, less sensitive to the independent assp)
#extension 1. can be applied to numerical prediction using kernel(non-para) function (use cv cross- info gain for the choose of kernel width)
reference: http://www.cs.waikato.ac.nz/~eibe/pubs/nbr.pdf
#extension 2. multi-classification
#extension 3. Feature selection to improve NB algorithm One option DT reference: http://alumni.cs.ucr.edu/~ratana/DCAP02.pdf/ maybe RF also can 


